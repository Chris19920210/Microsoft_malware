# -*- coding: utf-8 -*-
import sys
import math
import numpy as np
from sklearn.grid_search import GridSearchCV, RandomizedSearchCV
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score
import os
from sklearn import linear_model, datasets, metrics
from sklearn.cross_validation import train_test_split
from xgboost.sklearn import XGBClassifier
import argparse
import pandas as pd
from sklearn.feature_selection import SelectFromModel
from sklearn.ensemble import RandomForestClassifier

parser = argparse.ArgumentParser(description='tuning various models')
parser.add_argument('--dataset', type=str, required=True,
                    help='dataset directory')
parser.add_argument('--num-tree', nargs='+', type=int, default=[100, 101, 1],
                    help='# of trees for tree based methods')
parser.add_argument('--depths', nargs='+', type=int, default=[3, 4, 1],
                    help='depths for tree based methods')
parser.add_argument('--lr', nargs='+', type=float, default=[1, 2, 1],
                    help='learning rate for gradient based model')
parser.add_argument('--subsample', nargs='+', type=float, default=[1, 2, 1],
                    help='subsample for each node cut')
parser.add_argument('--colsample', nargs='+', type=float, default=[1, 2, 1],
                    help='col_subsample for each node cut')
parser.add_argument('--iter', type=int, default=20,
                    help='# of random sample')
parser.add_argument('--threshold', nargs='+', type=float, default=[1, 1.1, 0.12],
                   help='threshold for feature selection e.g (1*median)')
parser.add_argument('--components',nargs='+', type= int, default=[100,101,1],
                    help='# of components for tree-based feature selector')
args = parser.parse_args()


def main():
    data = pd.read_csv(args.dataset)
    X = data.drop(['Id', 'Class'], axis=1)
    Y = data.loc[:, 'Class']
    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)
    estimator = [('reduce_dim', SelectFromModel(RandomForestClassifier())), ('classifier', XGBClassifier())]
    # transform the threshold to the quantile of median
    tmp = map(str, np.arange(args.threshold[0],args.threshold[1],args.threshold[2]))
    threshold = map(lambda x: x+'*median', tmp)
    clf = Pipeline(estimator)
    params = {}
    params['reduce_dim__estimator__n_estimators'] = list(np.arange(args.components[0], args.components[1], args.components[2]))
    params['reduce_dim__threshold'] = threshold
    params['classifier__n_estimators'] = list(np.arange(args.num_tree[0], args.num_tree[1], args.num_tree[2]))
    params['classifier__max_depth'] = list(np.arange(args.depths[0], args.depths[1], args.depths[2]))
    params['classifier__learning_rate'] = list(np.arange(args.lr[0], args.lr[1], args.lr[2]))
    params['classifier__subsample'] = list(np.arange(args.subsample[0], args.subsample[1], args.subsample[2]))
    params['classifier__colsample_bytree'] = list(np.arange(args.colsample[0], args.colsample[1], args.colsample[2]))
    # Cross_validation for grid search
    try:
        grid_search = RandomizedSearchCV(clf, param_distributions=params, n_iter=args.iter, cv=5, n_jobs=-1)
        grid_search.fit(X_train, y_train)
    except:
        grid_search = GridSearchCV(clf, param_grid=params, cv=5, n_jobs=-1)
        grid_search.fit(X_train, y_train)
    best_parameters, score, _ = max(grid_search.grid_scores_, key=lambda x: x[1])
    result = accuracy_score(y_test, grid_search.predict(X_test))
    print("Predict Accuracy: " + str(result))
    print("XGboost using raw pixel features:\n%s\n" % (metrics.classification_report(y_test, grid_search.predict(X_test))))
    print best_parameters



if __name__ == '__main__':
    main()

