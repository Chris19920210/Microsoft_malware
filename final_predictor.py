import sys
import math
import numpy as np
from sklearn.grid_search import GridSearchCV
import xgboost as xgb
from xgboost.sklearn import XGBClassifier
from sklearn.neural_network import BernoulliRBM
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score
import os
from sklearn import linear_model, datasets, metrics
from sklearn.cross_validation import train_test_split
import pandas as pd
from sklearn.grid_search import RandomizedSearchCV, GridSearchCV
from xgboost.sklearn import XGBClassifier


parser = argparse.ArgumentParser(description='save predictor')
parser.add_argument('--train-dataset', type=str, required=True,
                    help='train dataset directory')
parser.add_argument('--test-dataset', type=str, required=True,
                    help='test dataset directory')
parser.add_argument('--save-dir', type=str, required=True,
                    help='save the pickle')
parser.add_argument('--best-estimator',type=int,required=True,
                    help='n_estimator by cv')
parser.add_argument('--best-depth',type=int,required=True,
                    help='max_depth by cv')
parser.add_argument('--best-subsample',type=float,required=True,
                    help='subsample by cv')
parser.add_argument('--best-colsample',type=float,required=True,
                    help='colsample by cv')
parser.add_argument('--best-lr',type=float,required=True,
                    help='learning rate by cv')
args = parser.parse_args()

# best hyperparameters by randomized cross validation

best_dicts = {
'n_estimators':args.best_estimator,
'max_depth': args.best_depth,
'subsample':args.best_subsample,
'learning_rate':args.best_lr,
'colsample_bytree':args.best_colsample
}


def main():
    data_train = pd.read_csv(args.train_dataset)
    X_train = data_train.drop(['Id', 'Class'], axis=1)
    y_train = data_train.loc[:, 'Class']
    data_test = pd.read_csv(args.test_dataset)
    X_test = data_test.drop(['Id'], axis=1)
    Id = data_test.loc[:, 'Id']
    clf = XGBClassifier()
    clf.set_params(**best_dicts)
    clf.fit(X_train, y_train)
    prediction = clf.predict_proba(X_test)
    columns = ['Prediction'+str(i) for i in range(1, 10)]
    prediction = pd.DataFrame(prediction, columns=columns)
    results = pd.concat([Id, prediction], axis=1)
    return (clf, results)



if __name__ == '__main__':
    clf, result = main()
    # save the result
    results.to_csv(os.path.join(args.save_dir, 'test_results.csv'), index=False)
    # save the classifier for reproducing
    pickle.dump(clf, open(os.path.join(args.save_dir,"Microsoft_final_model.p"), "wb"))







